{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER Elmo",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Munya07/NLP/blob/master/2.NER/Elmo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pe7drwwTu5n",
        "colab_type": "code",
        "outputId": "b2fb6119-07e9-4420-bef6-b048346f5cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Keras==1.0.6\n",
        "import numpy as np\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.core import  Activation\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
        "import tensorflow_hub as hub\n",
        "from keras.layers import Dense,TimeDistributed\n",
        "import keras.layers as layers\n",
        "from keras.models import Model,Sequential\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras.layers import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0606 06:05:06.974101 139669616666496 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IfMY9KkTu5u",
        "colab_type": "code",
        "outputId": "003c5716-a26a-4936-cab1-3e2c66e9618e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "raw = open('drive/My Drive/elmo/wikigold.conll.txt', 'r').readlines()\n",
        " \n",
        "all_x = []\n",
        "point = []\n",
        "for line in raw:\n",
        "    stripped_line = line.strip().split(' ')\n",
        "    point.append(stripped_line)\n",
        "    if line == '\\n':\n",
        "        all_x.append(point[:-1])\n",
        "        point = []\n",
        "all_x = all_x[:-1]\n",
        " \n",
        "lengths = [len(x) for x in all_x]\n",
        "print('Input sequence length range: ', max(lengths), min(lengths))\n",
        " \n",
        "short_x = [x for x in all_x if len(x) < 64]\n",
        " \n",
        "X = [[c[0] for c in x] for x in short_x]\n",
        "y = [[c[1] for c in y] for y in short_x]\n",
        " \n",
        "all_text = [c for x in X for c in x]\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9441c28e1f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/elmo/wikigold.conll.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/elmo/wikigold.conll.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8b4NwD4Tu50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = list(set(all_text))\n",
        "word2ind = {word: index for index, word in enumerate(words)}\n",
        "ind2word = {index: word for index, word in enumerate(words)}\n",
        "labels = list(set([c for x in y for c in x]))\n",
        "label2ind = {label: (index + 1) for index, label in enumerate(labels)}\n",
        "ind2label = {(index + 1): label for index, label in enumerate(labels)}\n",
        "print('Vocabulary size:', len(word2ind), len(label2ind))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xZ7J32WTu55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = max([len(x) for x in X])\n",
        "print('Maximum sequence length:', maxlen)\n",
        "print(label2ind)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a3GQVLQTu6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(x, n):\n",
        "    result = np.zeros(n)\n",
        "    result[x] = 1\n",
        "    return result\n",
        " \n",
        "X_enc = [[word2ind[c] for c in x] for x in X]\n",
        "max_label = max(label2ind.values()) + 1\n",
        "y_enc = [[0] * (maxlen - len(ey)) + [label2ind[c] for c in ey] for ey in y]\n",
        "y_enc = [[encode(c, max_label) for c in ey] for ey in y_enc]\n",
        " \n",
        "X_enc = pad_sequences(X_enc, maxlen=maxlen)\n",
        "y_enc = pad_sequences(y_enc, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eopEccilTu6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_enc, y_enc, test_size=11*32, train_size=45*32, random_state=42)\n",
        "print('Training and testing tensor shapes:', X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
        " \n",
        "max_features = len(word2ind)\n",
        "embedding_size = 300\n",
        "hidden_size = 32\n",
        "out_size = len(label2ind) + 1\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFYScg2lTu6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfhMMI18Tu6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "K.set_session(sess)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "sess.run(tf.tables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfDjrFuvTu6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class ELMoEmbedding(Layer):\n",
        "\n",
        "    def __init__(self, idx2word, output_mode=\"default\", trainable=True, **kwargs):\n",
        "        assert output_mode in [\"default\", \"word_emb\", \"lstm_outputs1\", \"lstm_outputs2\", \"elmo\"]\n",
        "        assert trainable in [True, False]\n",
        "        self.idx2word = idx2word\n",
        "        self.output_mode = output_mode\n",
        "        self.trainable = trainable\n",
        "        self.max_length = None\n",
        "        self.word_mapping = None\n",
        "        self.lookup_table = None\n",
        "        self.elmo_model = None\n",
        "        self.embedding = None\n",
        "        super(ELMoEmbedding, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.max_length = input_shape[1]\n",
        "        self.word_mapping = [x[1] for x in sorted(self.idx2word.items(), key=lambda x: x[0])]\n",
        "        self.lookup_table = tf.contrib.lookup.index_to_string_table_from_tensor(self.word_mapping, default_value=\"<UNK>\")\n",
        "        self.lookup_table.init.run(session=K.get_session())\n",
        "        self.elmo_model = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=self.trainable)\n",
        "        super(ELMoEmbedding, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        x = tf.cast(x, dtype=tf.int64)\n",
        "        sequence_lengths = tf.cast(tf.count_nonzero(x, axis=1), dtype=tf.int32)\n",
        "        strings = tf.squeeze(self.lookup_table.lookup(x))\n",
        "        inputs = {\n",
        "            \"tokens\": strings,\n",
        "            \"sequence_len\": sequence_lengths\n",
        "        }\n",
        "        return self.elmo_model(inputs, signature=\"tokens\", as_dict=True)[self.output_mode]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.output_mode == \"default\":\n",
        "            return (input_shape[0], 1024)\n",
        "        if self.output_mode == \"word_emb\":\n",
        "            return (input_shape[0], self.max_length, 512)\n",
        "        if self.output_mode == \"lstm_outputs1\":\n",
        "            return (input_shape[0], self.max_length, 1024)\n",
        "        if self.output_mode == \"lstm_outputs2\":\n",
        "            return (input_shape[0], self.max_length, 1024)\n",
        "        if self.output_mode == \"elmo\":\n",
        "            return (input_shape[0], self.max_length, 1024)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'idx2word': self.idx2word,\n",
        "            'output_mode': self.output_mode \n",
        "        }\n",
        "        return list(config.items())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a30Y87sPTu6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_input = Input(shape=(X_train.shape[1],), dtype=tf.int64)\n",
        "sentence_embedding = ELMoEmbedding(idx2word=ind2word, output_mode=\"elmo\", trainable=True)(sentence_input) # These two are interchangeable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9hPGaZaTu6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout = Dropout(0.5)(sentence_embedding)\n",
        "lstm_ = LSTM(hidden_size,batch_size=batch_size, return_sequences=True)(sentence_embedding)\n",
        "timed_ = layers.TimeDistributed(layers.Dense(out_size))(lstm_)\n",
        "pred = layers.Activation('softmax')(timed_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMjjKaSOTu6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=[sentence_input], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx7qIPojTu6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10, validation_data=(X_test, y_test))\n",
        "score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print('Raw test score:', score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VozFBHuPTu6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score(yh, pr):\n",
        "    coords = [np.where(yhh > 0)[0][0] for yhh in yh]\n",
        "    yh = [yhh[co:] for yhh, co in zip(yh, coords)]\n",
        "    ypr = [prr[co:] for prr, co in zip(pr, coords)]\n",
        "    fyh = [c for row in yh for c in row]\n",
        "    fpr = [c for row in ypr for c in row]\n",
        "    return fyh, fpr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz3sa4K9Tu6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prob = model.predict(X_train) \n",
        "y_classes = y_prob.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMjONeG6Tu6o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3sVUX7cTu6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_classes[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP7LF-eATu6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yh = y_train.argmax(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRTjU2-gTu6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pr=y_classes\n",
        "fyh, fpr = score(yh, pr)\n",
        "print('Training accuracy:', accuracy_score(fyh, fpr))\n",
        "print('Training confusion matrix:')\n",
        "print(confusion_matrix(fyh, fpr))\n",
        "precision_recall_fscore_support(fyh, fpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h6064FLTu62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1dtgQqhTu65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prob = model.predict(X_test) \n",
        "pr = y_prob.argmax(axis=-1)\n",
        "yh = y_test.argmax(2)\n",
        "fyh, fpr = score(yh, pr)\n",
        "print('Testing accuracy:', accuracy_score(fyh, fpr))\n",
        "print('Testing confusion matrix:')\n",
        "print(confusion_matrix(fyh, fpr))\n",
        "precision_recall_fscore_support(fyh, fpr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_Vz7rY_Tu6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "string = \"John was a member of US Army\"\n",
        "wordlist1 = string.split(' ')\n",
        "ip = []\n",
        "for x in wordlist:\n",
        "    ip.append(word2ind[x])\n",
        "i=maxlen-len(ip)\n",
        "temp=[0]*i\n",
        "ip1=temp+ip\n",
        "\n",
        "string = \"US Army is war\"\n",
        "wordlist2 = string.split(' ')\n",
        "ip = []\n",
        "for x in wordlist:\n",
        "    ip.append(word2ind[x])\n",
        "i=maxlen-len(ip)\n",
        "temp=[0]*i\n",
        "ip2=temp+ip\n",
        "\n",
        "\n",
        "input_layer = model.layers[1].input\n",
        "output_layer = model.layers[4].output\n",
        "op = K.function([input_layer], [output_layer])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEMiHYUxTu7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xxxxx=[ip1,ip2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWNO_XvNTu7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ttt=np.array(xxxxx,dtype=np.int32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3gqTX14Tu7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ttt.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeMdo5bvTu7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_prob2 = model.predict(X_test[10:14]) \n",
        "#pr2 = y_prob.argmax(axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZNv836TTu7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = op([ttt])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGEjgoBOTu7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out[0][0]\n",
        "out[0][1].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs57R_VlTu7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=maxlen-len(ip1)\n",
        "\n",
        "temp = []\n",
        "while i<maxlen:\n",
        "    for j in label2ind:        \n",
        "        #if label2ind[j]==out[0][0][i].tolist().index(max(out[0][0][i])):\n",
        "        if label2ind[j]==out[0][0][i].tolist().index(max(out[0][0][i])):\n",
        "            temp.append(j)\n",
        "    i=i+1\n",
        "print(wordlist1)\n",
        "print(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM0vnZS0Tu7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=maxlen-len(ip2)\n",
        "\n",
        "temp = []\n",
        "while i<maxlen:\n",
        "    for j in label2ind:        \n",
        "        #if label2ind[j]==out[0][0][i].tolist().index(max(out[0][0][i])):\n",
        "        if label2ind[j]==out[0][1][i].tolist().index(max(out[0][1][i])):\n",
        "            temp.append(j)\n",
        "    i=i+1\n",
        "print(wordlist2)\n",
        "print(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqP06k7yTu7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(ip1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}